import os
import requests
import google.generativeai as genai
from datetime import datetime, timedelta, timezone
import glob
import re

# 1. API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

def get_all_past_titles(target_category="research"):
    """
    _posts í´ë” ë‚´ì˜ ëª¨ë“  íŒŒì¼ì„ í™•ì¸í•˜ì—¬,
    íŠ¹ì • ì¹´í…Œê³ ë¦¬ì— ì†í•œ ê²Œì‹œê¸€ì˜ 'ì œëª©(Title)' ëª©ë¡ì„ ì „ë¶€ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    titles = []
    # ëª¨ë“  md íŒŒì¼ íƒìƒ‰
    files = glob.glob('_posts/*.md')
    
    # ì¹´í…Œê³ ë¦¬ í™•ì¸ìš© ì •ê·œì‹ (researchê°€ í¬í•¨ëœ ëŒ€ê´„í˜¸ ì°¾ê¸°)
    category_pattern = re.compile(r"categories:\s*\[?[^\]\n]*" + re.escape(target_category) + r"[^\]\n]*\]?")
    # ì œëª© ì¶”ì¶œìš© ì •ê·œì‹ (title: "..." ë˜ëŠ” title: ... í˜•íƒœ)
    title_pattern = re.compile(r"title:\s*[\"']?([^\"'\n]+)[\"']?")

    for file_path in files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                parts = content.split('---')
                
                if len(parts) >= 3:
                    front_matter = parts[1]
                    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš°ì—ë§Œ ì œëª© ì¶”ì¶œ
                    if category_pattern.search(front_matter):
                        match = title_pattern.search(front_matter)
                        if match:
                            # [Research] íƒœê·¸ ë“±ì´ ìˆë‹¤ë©´ ì œê±°í•˜ê³  ìˆœìˆ˜ ì œëª©ë§Œ ë‚¨ê¸°ëŠ” ê²ƒì´ ì¢‹ìŒ (ì„ íƒì‚¬í•­)
                            clean_title = match.group(1).strip()
                            titles.append(clean_title)
        except Exception:
            continue
            
    return titles

def get_naver_papers():
    """ë„¤ì´ë²„ ì „ë¬¸ìë£Œ(í•™ìˆ ë…¼ë¬¸ ë“±) ê²€ìƒ‰"""
    url = "https://openapi.naver.com/v1/search/doc.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    raw_query = '(urban|smart city|environment|traffic|data)'
    params = {
        "query": raw_query,
        "display": 50, # ë¹„êµ ëŒ€ìƒì„ ë§ì´ ê°€ì ¸ì˜´
        "start": 1,
        "sort": "date"
    }
    
    try:
        response = requests.get(url, headers=headers, params=params)
        if response.status_code == 200:
            items = response.json().get('items', [])
            paper_list = []
            for item in items:
                title = item['title'].replace("<b>", "").replace("</b>", "")
                desc = item['description'].replace("<b>", "").replace("</b>", "")
                paper_list.append({
                    "title": title,
                    "link": item['link'],
                    "description": desc
                })
            return paper_list
        return []
    except:
        return []

def run_research_agent():
    # 1. ë„¤ì´ë²„ì—ì„œ ìµœì‹  ë…¼ë¬¸ ê²€ìƒ‰
    papers = get_naver_papers()
    
    # 2. ë¸”ë¡œê·¸ì— ì´ë¯¸ ì‘ì„±ëœ ëª¨ë“  ê¸€ì˜ ì œëª© ê°€ì ¸ì˜¤ê¸°
    past_titles = get_all_past_titles(target_category="research")
    
    # ë‚ ì§œ ì„¤ì •
    kst = timezone(timedelta(hours=9))
    now = datetime.now(kst)
    today_file = now.strftime("%Y-%m-%d")
    today_display = now.strftime("%Y/%m/%d")

    # ì´ë¯¸ ì‘ì„±ëœ ì œëª©ë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    past_titles_str = "\n".join([f"- {t}" for t in past_titles]) if past_titles else "ì—†ìŒ (ì²« ê¸€ ì‘ì„±)"

    if papers:
        prompt = f""" 
        ë„ˆëŠ” ë„ì‹œê³µí•™ê³¼ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ë¥¼ ê³µë¶€í•˜ëŠ” IT ì „ê³µ 3í•™ë…„ í•™ë¶€ ì—°êµ¬ìƒì´ì•¼.
        ì•„ë˜ [ìˆ˜ì§‘ëœ ë°ì´í„°] ëª©ë¡ì—ì„œ **ë¸”ë¡œê·¸ì— í¬ìŠ¤íŒ…í•  ê°€ì¥ ê°€ì¹˜ ìˆëŠ” ë…¼ë¬¸ 1ê°œ**ë¥¼ ì„ ì •í•´ì¤˜.

        [ì¤‘ë³µ ë°©ì§€ ê·œì¹™ - ë§¤ìš° ì¤‘ìš”!]
        ì•„ë˜ [ì´ë¯¸ ì‘ì„±ëœ ë…¼ë¬¸ ëª©ë¡]ì— ìˆëŠ” ì œëª©ê³¼ ê²¹ì¹˜ëŠ” ë…¼ë¬¸ì€ **ì ˆëŒ€ ì„ ì •í•˜ì§€ ë§ˆ.**

        [ì´ë¯¸ ì‘ì„±ëœ ë…¼ë¬¸ ëª©ë¡]
        {past_titles_str}

        [ìˆ˜ì§‘ëœ ë°ì´í„° (ê²€ìƒ‰ ê²°ê³¼)]
        {papers}

        [í•„ìˆ˜ ìš”ì²­ ì‚¬í•­]
        1. **ì²« ì¤„ ì¶œë ¥**: ë§¨ ì²« ì¤„ì— `TITLE: ì„ ì •ëœ ë…¼ë¬¸ ì œëª©` í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•  ê²ƒ. (ì´ ì œëª©ì´ ë¸”ë¡œê·¸ ê¸€ ì œëª©ì´ ë¨)
        2. **ë³¸ë¬¸ ì‘ì„±**: ë‘˜ì§¸ ì¤„ë¶€í„° ë°”ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ë‚´ìš© ì‘ì„±.

        [ì‘ì„± ê°€ì´ë“œë¼ì¸]
        1. **ë…ì íƒ€ê²Ÿ**: í•™ë¶€ìƒ ë™ê¸°ë“¤ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ (ì–´ë ¤ìš´ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…).
        2. **êµ¬ì„±**:
            - **ë…¼ë¬¸ ì›ì œ ë° ë§í¬**: (ì •í™•í•œ ì¶œì²˜ í‘œê¸°)
            - **ğŸ™ï¸ Problem (ì™œ ì¤‘ìš”í•´?)**: ë„ì‹œ ë¬¸ì œì™€ì˜ ì—°ê²°ê³ ë¦¬.
            - **ğŸ” Solution (ì–´ë–»ê²Œ í’€ì—ˆì–´?)**: ë°ì´í„°ì™€ ë°©ë²•ë¡  (í•µì‹¬ ìœ„ì£¼).
            - **ğŸ’¡ Result (ê²°ê³¼ëŠ”?)**: ì‹œì‚¬ì .
            - **ğŸš€ Growth (ë” ê³µë¶€í•  ê²ƒ)**: ì—°ê´€ í‚¤ì›Œë“œ.
        """
    else:
        prompt = "ìŠ¤ë§ˆíŠ¸ì‹œí‹° ê´€ë ¨ ìµœì‹  ë…¼ë¬¸ì´ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `TITLE: ìŠ¤ë§ˆíŠ¸ì‹œí‹° ê¸°ìˆ  ì—°êµ¬ ë™í–¥` ìœ¼ë¡œ ì œëª©ì„ ì¡ê³  ì¼ë°˜ì ì¸ ìµœì‹  íŠ¸ë Œë“œë¥¼ ì •ë¦¬í•´ì¤˜."

    # Gemini í˜¸ì¶œ
    response = model.generate_content(prompt)
    raw_text = response.text.strip()

    # --- ì œëª© ì¶”ì¶œ ë° ë³¸ë¬¸ ë¶„ë¦¬ ---
    lines = raw_text.split('\n')
    final_title = f"{today_display} ë„ì‹œÂ·í™˜ê²½ IT ì—°êµ¬ ë…¸íŠ¸"
    body_content = raw_text

    if lines and lines[0].startswith("TITLE:"):
        extracted_title = lines[0].replace("TITLE:", "").strip()
        final_title = extracted_title.replace('"', '').replace("'", "")
        body_content = "\n".join(lines[1:]).strip()
    
    # --- íŒŒì¼ ì €ì¥ ---
    os.makedirs("_posts", exist_ok=True)
    file_name = f"_posts/{today_file}-urban-research.md"
    slug = f"urban-research-{today_file}"

    with open(file_name, "w", encoding="utf-8") as f:
        f.write("---\n")
        f.write("layout: single\n")
        f.write(f"title: \"[Research] {final_title}\"\n") # AIê°€ ë½‘ì€ ì œëª© ì‚¬ìš©
        f.write(f"date: {today_file}\n")
        f.write("categories: [research]\n")
        f.write(f"slug: \"{slug}\"\n")
        f.write("---\n\n")
        f.write(body_content)
    
    print(f"ë°œí–‰ ì™„ë£Œ: {file_name}")
    print(f"ì„ ì •ëœ ì œëª©: {final_title}")
    print(f"ì œì™¸ëœ ê³¼ê±° ëª©ë¡ ê°œìˆ˜: {len(past_titles)}ê°œ")

if __name__ == "__main__":
    run_research_agent()
